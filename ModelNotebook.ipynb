{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelNotebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AahanGhode/AahanGhode/blob/main/ModelNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBsDPXc1PcEo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "import os, shutil"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data gathering and preprocessing**"
      ],
      "metadata": {
        "id": "0rKUvJI2pCnR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVrNa5CBbft5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048654c5-e2b3-4968-e819-38627a15e640"
      },
      "source": [
        "try:\n",
        " shutil.rmtree(\"/content/covid-classification-ml\", ignore_errors=False, onerror=None)\n",
        "except:\n",
        "  print(\"An error occurred\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcQJsEL1PKvA",
        "outputId": "2d5c4385-ac00-4851-8e2f-ea9a24f064c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/cardstdani/covid-classification-ml.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'covid-classification-ml'...\n",
            "remote: Enumerating objects: 29443, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 29443 (delta 7), reused 21 (delta 4), pack-reused 29419\u001b[K\n",
            "Receiving objects: 100% (29443/29443), 4.06 GiB | 34.73 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "Updating files: 100% (23476/23476), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcayEf-oOoGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b44f1f9-07ff-4bcb-b67b-c7377e09f58b"
      },
      "source": [
        "DIR = \"/content/covid-classification-ml/Covid19_Dataset\"\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, subset=\"training\", seed=42, batch_size=32, smart_resize=True, image_size=(256, 256))\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, subset=\"validation\", seed=42, batch_size=32, smart_resize=True, image_size=(256, 256))\n",
        "\n",
        "classes = train_dataset.class_names\n",
        "numClasses = len(train_dataset.class_names)\n",
        "print(classes)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 23472 files belonging to 5 classes.\n",
            "Using 21125 files for training.\n",
            "Found 23472 files belonging to 5 classes.\n",
            "Using 2347 files for validation.\n",
            "['Bacterial Pneumonia', 'COVID', 'Normal', 'Tuberculosis', 'Viral Pneumonia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<b>Data augmentation</b>"
      ],
      "metadata": {
        "id": "iikjEcDTgvKl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyufTsjIwiFx",
        "outputId": "13b1cb88-9592-4e58-ad85-c0078ded0066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  #tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<b>Model Training</b>"
      ],
      "metadata": {
        "id": "4O1Uu_Dyg0kI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b814c2ad-c99d-450f-c8db-3ad8f7e45e9b",
        "id": "dJ9l7_GE4OFC"
      },
      "source": [
        "baseModel = tf.keras.applications.MobileNetV3Small(input_shape=(256, 256,3), weights='imagenet', include_top=False, classes=numClasses)\n",
        "last_output = baseModel.layers[-1].output\n",
        "x = tf.keras.layers.Dropout(0.5) (last_output)\n",
        "x = tf.keras.layers.GlobalMaxPooling2D() (last_output)\n",
        "x = tf.keras.layers.Dense(256, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.02), activity_regularizer=tf.keras.regularizers.l2(0.02),  kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.BatchNormalization() (x)\n",
        "x = tf.keras.layers.Dropout(0.45) (x)\n",
        "x = tf.keras.layers.Dense(numClasses, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=baseModel.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "epochs = 40\n",
        "timeDecay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * 1 / (1 + 10 * epoch))\n",
        "stepDecay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.1 * 0.1**math.floor(epoch / 6))\n",
        "history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs, callbacks=[stepDecay])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            " 12/661 [..............................] - ETA: 28:40 - loss: 243.4696 - accuracy: 0.4089"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__aMYI6-OusN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "090de84c-b89a-4fc0-8bad-a1f91214058e"
      },
      "source": [
        "plt.plot(range(0, epochs), history.history[\"loss\"], color=\"b\", label=\"Loss\")\n",
        "plt.plot(range(0, epochs), history.history[\"val_loss\"], color=\"r\", label=\"Test Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-803407e25d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxNiwavZj-We"
      },
      "source": [
        "plt.plot(range(0, epochs), history.history[\"accuracy\"], color=\"b\", label=\"Accuracy\")\n",
        "plt.plot(range(0, epochs), history.history[\"val_accuracy\"], color=\"r\", label=\"Test Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Model Architecture and Management</b>"
      ],
      "metadata": {
        "id": "3sOWIIZeg653"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OAZnrIoRbKMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjjNM9Vhz6xE"
      },
      "source": [
        "model = tf.keras.models.load_model(\"/content/covid-classification-ml/XrayClassificationModel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB6Fcx_tBM0W"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W0S8gUoOxlV",
        "outputId": "4af7f598-34d4-4563-b28f-45b7cbeb6c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "model.save(\"/content/model.h5\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0474d5942f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting to JS graph model\n",
        "!pip install tensorflowjs\n",
        "!tensorflowjs_converter --input_format=keras --output_format=tfjs_graph_model /content/covid-classification-ml/XrayClassificationModel.h5 /content/XrayModelJS"
      ],
      "metadata": {
        "id": "ij2bsYT5a98N",
        "outputId": "757b71ef-9734-47da-924f-a1665f2638bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (3.19.6)\n",
            "Requirement already satisfied: tensorflow<3,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (2.11.0)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (0.4.4)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (5.12.0)\n",
            "Collecting packaging~=20.9\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-decision-forests>=1.0.1\n",
            "  Downloading tensorflow_decision_forests-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax>=0.6.2\n",
            "  Downloading flax-0.6.6-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich>=11.1\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (4.5.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (1.0.4)\n",
            "Collecting orbax\n",
            "  Downloading orbax-0.1.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.2/74.2 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (3.5.3)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (1.22.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (6.0)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorstore\n",
            "  Downloading tensorstore-0.1.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib_resources>=5.9.0->tensorflowjs) (3.15.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.31.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (15.0.6.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.11.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (23.1.21)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.51.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from tensorflow-decision-forests>=1.0.1->tensorflowjs) (1.3.5)\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from tensorflow-decision-forests>=1.0.1->tensorflowjs) (0.38.4)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (4.38.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (8.4.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax->flax>=0.6.2->tensorflowjs) (0.4.4+cuda11.cudnn82)\n",
            "Collecting chex>=0.1.5\n",
            "  Downloading chex-0.1.6-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached_property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.8/dist-packages (from orbax->flax>=0.6.2->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->tensorflow-decision-forests>=1.0.1->tensorflowjs) (2022.7.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (6.0.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: cached_property, wurlitzer, tensorstore, pygments, packaging, mdurl, markdown-it-py, rich, chex, optax, tensorflow-decision-forests, orbax, flax, tensorflowjs\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.0\n",
            "    Uninstalling packaging-23.0:\n",
            "      Successfully uninstalled packaging-23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cached_property-1.5.2 chex-0.1.6 flax-0.6.6 markdown-it-py-2.2.0 mdurl-0.1.2 optax-0.1.4 orbax-0.1.3 packaging-20.9 pygments-2.14.0 rich-13.3.1 tensorflow-decision-forests-1.2.0 tensorflowjs-4.2.0 tensorstore-0.1.33 wurlitzer-3.0.3\n",
            "2023-03-04 15:40:01.697794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-04 15:40:01.697984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-04 15:40:01.698018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorflowjs_converter\", line 8, in <module>\n",
            "    sys.exit(pip_main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflowjs/converters/converter.py\", line 827, in pip_main\n",
            "    main([' '.join(sys.argv[1:])])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflowjs/converters/converter.py\", line 831, in main\n",
            "    convert(argv[0].split(' '))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflowjs/converters/converter.py\", line 817, in convert\n",
            "    _dispatch_converter(input_format, output_format, args, quantization_dtype_map,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflowjs/converters/converter.py\", line 508, in _dispatch_converter\n",
            "    dispatch_keras_h5_to_tfjs_graph_model_conversion(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflowjs/converters/converter.py\", line 136, in dispatch_keras_h5_to_tfjs_graph_model_conversion\n",
            "    raise ValueError('Nonexistent path to HDF5 file: %s' % h5_path)\n",
            "ValueError: Nonexistent path to HDF5 file: /content/covid-classification-ml/XrayClassificationModel.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<b>Evaluation</b>"
      ],
      "metadata": {
        "id": "RLOzntcqZ5SE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgN8eqKzpGdh"
      },
      "source": [
        "**One Image Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoqWrT3vjNsQ",
        "outputId": "f35157cf-93a7-4265-d2ef-ec9bdeed6fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import requests\n",
        "\n",
        "img_data = requests.get(\"https://cdn0.scrvt.com/0e46935d037de4ec3888566275864b37/1800000007267893/5a55409c371b/v/f8eac2053bc7/x-ray-COVID-19-2_1800000007267893.jpg?nowebp=1\").content\n",
        "with open('img.jpg', 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "\n",
        "path = \"/content/img.jpg\"\n",
        "#path = \"/content/Covid19_Dataset/Normal/Normal-1000.png\"\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(path, target_size=(256, 256))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) \n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "plt.imshow(img)\n",
        "print(predictions[0]*100, \"\\n\", classes)\n",
        "print(\"Prediction: \", classes[np.argmax(predictions)], f\"{predictions[0][np.argmax(predictions)]*100}%\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5c5ec0c9accf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgPjBYc3pKz3"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxHXWGubTos1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f47332e9-083f-4aa4-98c9-387a04b67a8b"
      },
      "source": [
        "def plot_confusion_matrix(cm, target_names, cmap=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}%; misclass={:0.4f}%'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "true = []\n",
        "predictions = []\n",
        "\n",
        "for images, labels in test_dataset.take(1900):\n",
        "  pred = model.predict(images)\n",
        "  for i in range(32):\n",
        "    try:\n",
        "      ax = plt.subplot(4, 8, i + 1)\n",
        "      plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "      #print(classes[np.argmax(pred[i])], 100 * np.max(pred[i]), \"real = \" + str(classes[labels[i]]))\n",
        "\n",
        "      true.append(labels[i])\n",
        "      predictions.append(np.argmax(pred[i]))\n",
        "\n",
        "      plt.title(classes[labels[i]])\n",
        "      plt.axis(\"off\")\n",
        "    except:\n",
        "      print()\n",
        "\n",
        "\"\"\"path = \"/content/covid-classification-ml/Covid19_Dataset\"\n",
        "for i in os.listdir(path):\n",
        "  folderPath = os.path.join(path, i)\n",
        "  for j in os.listdir(folderPath)[:1500]:\n",
        "    fullPath = os.path.join(folderPath, j)\n",
        "    try:\n",
        "      img = tf.keras.preprocessing.image.load_img(fullPath, target_size=(256, 256))\n",
        "      img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      img_array = tf.expand_dims(img_array, 0) \n",
        "\n",
        "      preds = model.predict(img_array)\n",
        "      true.append(classes.index(i))\n",
        "      predictions.append(np.argmax(preds))\n",
        "      #print(fullPath)\n",
        "    except:\n",
        "      print(\"Error on image:\", fullPath)\"\"\"\n",
        "\n",
        "plot_confusion_matrix(tf.math.confusion_matrix(true, predictions), classes)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-70d6cd2ac0ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/covid-classification-ml/Covid19_Dataset\"\n",
        "for i in os.listdir(path):\n",
        "  folderPath = os.path.join(path, i)\n",
        "  for j in os.listdir(folderPath)[:]:\n",
        "    fullPath = os.path.join(folderPath, j)\n",
        "    print(i, classes.index(i))"
      ],
      "metadata": {
        "id": "OfL_BEL9NlVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ub9jdM3TUeL"
      },
      "source": [
        "**Filter visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZTcUzKgTUNZ",
        "outputId": "6a163d3f-6342-458a-c17f-46c53331f4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "img_path='/content/img.jpg' \n",
        "\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))# Convert ht image to Array of dimension (150,150,3)\n",
        "x   = tf.keras.preprocessing.image.img_to_array(img)                           \n",
        "x   = x.reshape((1,) + x.shape)# Rescale by 1/255\n",
        "x /= 255.0\n",
        "\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  print(feature_map.shape)\n",
        "  if len(feature_map.shape) == 4:       \n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "    \n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    \n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x# Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='winter' )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e5d914f3d9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/img.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msuccessive_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvisualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccessive_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Convert ht image to Array of dimension (150,150,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Advanced Activation Visualization </b>"
      ],
      "metadata": {
        "id": "i4bPXnEGaCMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import imutils\n",
        "\n",
        "class GradCAM:\n",
        "  def __init__(self, model, classIdx, layerName=None):\n",
        "    self.model = model\n",
        "    self.classIdx = classIdx\n",
        "    self.layerName = layerName\n",
        "    if self.layerName is None:\n",
        "      self.layerName = self.find_target_layer()\n",
        "   \n",
        "  def find_target_layer(self):\n",
        "    for layer in reversed(self.model.layers):\n",
        "      if len(layer.output_shape) == 4:\n",
        "        return layer.name\n",
        "    raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
        "\n",
        "  def compute_heatmap(self, image, eps=1e-8):\n",
        "    gradModel = Model(\n",
        "\t\t\tinputs=[self.model.inputs],\n",
        "\t\t\toutputs=[self.model.get_layer(self.layerName).output,\n",
        "\t\t\t\tself.model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "      inputs = tf.cast(image, tf.float32)\n",
        "      (convOutputs, predictions) = gradModel(inputs)\n",
        "      loss = predictions[:, self.classIdx]\n",
        "    grads = tape.gradient(loss, convOutputs)\n",
        "    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
        "    castGrads = tf.cast(grads > 0, \"float32\")\n",
        "    guidedGrads = castConvOutputs * castGrads * grads\n",
        "    convOutputs = convOutputs[0]\n",
        "    guidedGrads = guidedGrads[0]\n",
        "    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
        "    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
        "    (w, h) = (image.shape[2], image.shape[1])\n",
        "    heatmap = cv2.resize(cam.numpy(), (w, h))\n",
        "    numer = heatmap - np.min(heatmap)\n",
        "    denom = (heatmap.max() - heatmap.min()) + eps\n",
        "    heatmap = numer / denom\n",
        "    heatmap = (heatmap * 255).astype(\"uint8\")\n",
        "    return heatmap\n",
        "\n",
        "  def overlay_heatmap(self, heatmap, image, alpha=0.5, colormap=cv2.COLORMAP_VIRIDIS):\n",
        "    heatmap = cv2.applyColorMap(heatmap, colormap)\n",
        "    output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
        "    return (heatmap, output)\n",
        "\n",
        "path = \"/content/covid-classification-ml/Covid19_Dataset/Tuberculosis/Tuberculosis-310.png\"\n",
        "orig = cv2.imread(path)\n",
        "resized = cv2.resize(orig, (256, 256))\n",
        "\n",
        "image = tf.keras.preprocessing.image.load_img(path, target_size=(256, 256))\n",
        "image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "predictions = model.predict(image)\n",
        "cam = GradCAM(model, np.argmax(predictions[0]), \"expanded_conv_6/expand\")\n",
        "heatmap = cv2.resize(cam.compute_heatmap(image), (orig.shape[1], orig.shape[0]))\n",
        "\n",
        "#heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n",
        "(heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n",
        "\n",
        "#cv2.rectangle(output, (0, 0), (340, 40), (0, 0, 0), -1)\n",
        "cv2.putText(output, classes[np.argmax(predictions)], (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "output = np.vstack([orig, heatmap, output])\n",
        "output = imutils.resize(output, height=700)\n",
        "cv2_imshow(output)"
      ],
      "metadata": {
        "id": "2dtmCS33aBsI",
        "outputId": "d0498ae3-2f41-46e7-e00d-9857323f451b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4c0946436eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/covid-classification-ml/Covid19_Dataset/Tuberculosis/Tuberculosis-310.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    }
  ]
}